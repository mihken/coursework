{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn06OL82HeQU",
        "outputId": "bc9fee5c-fe80-4e27-c720-0b7be21dabb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Lambda\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers import Cropping2D\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D\n",
        "from keras import regularizers\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import plot_model\n",
        "import graphviz, pydot, pydotplus\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучение линейной модели, получение бейзлайна\n",
        "\n",
        "берем данные"
      ],
      "metadata": {
        "id": "4DJ-N4yOKHbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "measurements = []\n",
        "classifications = []\n",
        "\n",
        "root_folder = \"drive/MyDrive/h\"\n",
        "healthy = []\n",
        "for root, dirs, files in os.walk(root_folder):  \n",
        "    for filename in files:\n",
        "        healthy.append(filename)\n",
        "count_healthy = 0\n",
        "\n",
        "for i, name in enumerate(healthy):\n",
        "  if i>=3:\n",
        "    break\n",
        "  df = pd.read_csv(\"drive/MyDrive/h/\" + name, sep='\\t',skiprows=[0],\n",
        "  header=None, names=['X', 'Y', 'Wave', 'Intensity'])\n",
        "  for i in range(len(df)//1015):\n",
        "    measurements.append(df[['Intensity']][i*1015:(i+1)*1015].to_numpy())\n",
        "    classifications.append([1,0])\n",
        "    count_healthy += 1\n",
        "\n",
        "\n",
        "\n",
        "root_folder = \"drive/MyDrive/s\"\n",
        "sick = []\n",
        "for root, dirs, files in os.walk(root_folder):  \n",
        "    for filename in files:\n",
        "        sick.append(filename)\n",
        "\n",
        "count_sick = 0\n",
        "\n",
        "for i, name in enumerate(sick):\n",
        "  if i>=3:\n",
        "    break\n",
        "  df = pd.read_csv(\"drive/MyDrive/s/\" + name, sep='\\t',skiprows=[0],\n",
        "  header=None, names=['X', 'Y', 'Wave', 'Intensity'])\n",
        "  for i in range(len(df)//1015):\n",
        "    measurements.append(df[['Intensity']][i*1015:(i+1)*1015].to_numpy())\n",
        "    classifications.append([0,1])\n",
        "    count_sick += 1"
      ],
      "metadata": {
        "id": "Ql4piVWGJkj8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.asarray(measurements)\n",
        "y = np.asarray(classifications)\n",
        "X = X.reshape(X.shape[0], 1015)\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnYH417TOdtV",
        "outputId": "77ce540a-e5f6-4769-a217-422453d1c644"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2640, 1015)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=228)\n",
        "print(f'Total amount of train measurements: {X_train.shape}')\n",
        "print(f'Total amount of train labels: {y_train.shape}')\n",
        "print(f'Total amount of test measurements: {X_test.shape}')\n",
        "print(f'Total amount of test labels: {y_test.shape}')\n",
        "y_train_labels = np.argmax(y_train, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XosgHKTXL2Ii",
        "outputId": "b9e918b9-b9ae-46c3-cbce-8afe9d0beb0d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total amount of train measurements: (1980, 1015)\n",
            "Total amount of train labels: (1980, 2)\n",
            "Total amount of test measurements: (660, 1015)\n",
            "Total amount of test labels: (660, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "данные готовы \n",
        "\n",
        "переходим к обучению"
      ],
      "metadata": {
        "id": "JFxq1sdPOsri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n"
      ],
      "metadata": {
        "id": "30Nfp2KiKGjP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "m = LogisticRegression(max_iter=10000)\n",
        "m.fit(X_train, y_train_labels) \n",
        "\n",
        "print(f'LogisticRegression F1 Score {f1_score(y_test_labels, m.predict(X_test))}')\n",
        "print(f'LogisticRegression Accuracy {accuracy_score(y_test_labels, m.predict(X_test))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18qy2pLCMqTN",
        "outputId": "0947138f-f961-42ad-abf4-2c9a1f25b037"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression F1 Score 0.9098039215686274\n",
            "LogisticRegression Accuracy 0.8954545454545455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "теперь посмотрим результаты на других данных\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "iXWmsWYZQ6ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "pickle.dump(m, open('logistic_model_base', 'wb'))\n"
      ],
      "metadata": {
        "id": "I_qIKNfVQ_Cb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uqs-Cm9BWdRF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}